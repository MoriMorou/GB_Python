{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIAqr2CPdfJe"
   },
   "source": [
    "# Урок Х. Дополнительное занятие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Градиентный спуск и его виды\n",
    "\n",
    "- __классический с постоянным шагом__\n",
    "<img src=\"data/LX_Grad1.png\" style=\"width: 500px;\">\n",
    "Геометрическая интерпретация метода градиентного спуска с постоянным шагом: на каждом шаге мы сдвигаемся по вектору антиградиента, \"уменьшенному в $\\lambda$ раз\".\n",
    "\n",
    "\n",
    "- __с дроблением шага__\n",
    "<img src=\"data/LX_Grad2.png\" style=\"width: 800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __стохастический__\n",
    "\n",
    "В отличие от обычного градиентного спуска, градиент оптимизируемой функции считается на каждом шаге не как сумма градиентов от каждого элемента выборки, а как градиент от одного, случайно выбранного элемента, или же градиента от батча\n",
    "\n",
    "- __наискорейший__\n",
    "\n",
    "<img src=\"data/LX_Grad4_1.png\" style=\"width: 780px;\">\n",
    "<img src=\"data/LX_Grad4_2.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Шумы, выбросы, пропуски, смещение\n",
    "\n",
    "Методы предварительной обработки данных:\n",
    "\n",
    "- __очистка данных__ - является процессом обнаружения и исправления или удаления ошибочных записей данных\n",
    "- __нормализация данных__ - используется для стандартизации диапазона значений независимых переменных или признаков данных (сведение к интервалам [0, 1] или [-1, +1])\n",
    "- __преобразование данных__ - является процессом приведения данных в формат, который ожидают люди\n",
    "- __выделение признаков__ - является процессом преобразования входных данных в набор признаков, которые могут хорошо представлять входные данные\n",
    "- __уплотнение данных__ - является преобразованием числовых данных в исправленный, упорядоченный и упрощённый вид, что приводит к уменьшению количества или размерности данных\n",
    "\n",
    "Методы обнаружения выбросов:\n",
    "\n",
    "- __статистические подходы__ (box-plot, гистограмма и т.д.)\n",
    "- __модельные тесты__ (строим модель, описывающую данные, те объекты, что сильно выбиваются - выбросы)\n",
    "- __метрические методы__ (мерой аномальности может служить, например «расстояние до k-го соседа»)\n",
    "- __методы машинного обучения__\n",
    "    - __AdaBoost__ - выбросы набирают вес при построении новых моделей, решение - исключаем объекты из выборки, которые быстро набирают вес\n",
    "    - __метод опорных векторов для одного класса (OneClassSVM)__ - скорее алгоритм поиска новизны, а не выбросов, т.к. «затачивается» под обучающую выборку\n",
    "    - __изолирующий лес (IsolationForest)__ - одна из вариаций случайного леса, каждое дерево строится до исчерпании выборки, при разбиении выбирается случайные признак и расщепление, для каждого объекта мера его нормальности – среднее арифметическое глубин листьев, в которые он попал (изолировался)\n",
    "    - __эллипсоидальная аппроксимация данных (EllipticEnvelope)__ - облако точек моделируется как внутренность эллипсоида, метод хорошо работает только на одномодальных данных, а совсем хорошо – на нормально распределённых    \n",
    "\n",
    "Восстановление данных - заполнение пропусков:\n",
    "\n",
    "- __\"средние\"__: мат. ожидание, медиана, мода\n",
    "- __предсказание моделью__ (например, линейная регрессия)\n",
    "\n",
    "Смещение - __bias__ - матожидание разности между истинным ответом и выданным алгоритмом, т.е. E(f(х) – a). В ансамблях используют деревья, потому что они имеют низкий bias (\"выучивают\" выборку), а лес будет иметь тоже низкий bias, но из-за усреднения предсказаний деревьев имеет и низкий разброс - variance. Бустинговые алгоритмы предсказывают смещение предсказания предыдущих моделей, чтобы лучше приблизить верный ответ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Настройка гиперпараметров\n",
    "\n",
    "- \"Эль Классико\"\n",
    "    - __GridSearchCV__ - поиск по решетке, все комбинации\n",
    "    - __RandomizedSearchCV__ - случайный поиск\n",
    "- Продвинутые методы\n",
    "    - __байесовская оптимизация__ - стохастическая модель функции отображения из значений гиперпараметра в целевую функцию, ищется оптимальный набор гиперпараметров\n",
    "    - __оптимизация на основе градиентов__ - вычисление градиента гиперпараметров и оптимизация их с помощью градиентного спуска\n",
    "    - __эволюционные алгоритмы__ - начинаем со случайных, оцениваем пригодность, \"скрещиваем\" и \"мутируем\" слабые, повторяем до сходимости\n",
    "\n",
    "Популярные библиотеки:\n",
    "\n",
    "- __HyperOpt__ - автоматическая оптимизация гиперпараметров - https://github.com/hyperopt/hyperopt\n",
    "- __AutoML__ - автоматизирование workflow ML задач - http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
    "- __Spearmint__ и __BayesOpt__ - байесовская оптимизация - https://github.com/HIPS/Spearmint, https://rmcantin.bitbucket.io/html/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ценность ML\n",
    "\n",
    "Ценность ML = \"Прирост денег благодаря ML активности\" - \"Затраты на организацию всего процесса\"\n",
    "\n",
    "Для правильного использования ML в работе нужно следовать следующим шагам (в теории :)):\n",
    "\n",
    "1. Выявить, формализовать и определить важность проблемы\n",
    "2. Оценить реальность решения проблемы, возможные пути решения и выгоду от решения\n",
    "3. Расчитать трудозатраты на разработку решения и убедиться, что \"игра стоит свеч\"\n",
    "4. Доложить руководству содержимое пп. 1-3, \"защитить\" идея и \"выбить\" ресурсы на выполнение задачи\n",
    "5. Если вы все верно сделали в пп. 1-4, а руководитель счел ваши доводы весомыми, то можете начинать \"стакать иксджибусты\".\n",
    "6. Вы восхитительны!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Зануление весов маловажных признаков при L1-регуляризации\n",
    "\n",
    "Для понимания складываем три кусочка пазла:\n",
    "1. [Метод множителей Лагранжа](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BC%D0%BD%D0%BE%D0%B6%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%B9_%D0%9B%D0%B0%D0%B3%D1%80%D0%B0%D0%BD%D0%B6%D0%B0)\n",
    "2. [Условия Каруша — Куна — Таккера](https://ru.wikipedia.org/wiki/%D0%A3%D1%81%D0%BB%D0%BE%D0%B2%D0%B8%D1%8F_%D0%9A%D0%B0%D1%80%D1%83%D1%88%D0%B0_%E2%80%94_%D0%9A%D1%83%D0%BD%D0%B0_%E2%80%94_%D0%A2%D0%B0%D0%BA%D0%BA%D0%B5%D1%80%D0%B0)\n",
    "3. [Связный текст по теме](http://www.machinelearning.ru/wiki/images/7/7e/VetrovSem11_LARS.pdf)\n",
    " \n",
    "<img src=\"data/LX_L1.png\" style=\"width: 500px;\">\n",
    "Резюме идеи: \n",
    "\n",
    "- подбирая $\\lambda$, мы косвено решаем задачу Лагранжа \n",
    "- при L1 веса зануляются, так как оптимум приходится на точку на оси"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Weight of evidence (WoE) and Information value (IV)\n",
    "\n",
    "Метод преобразования признаков и их отбор, основные ссылки:\n",
    "1. Объяснение, преимущества, пример использования - [Weight of evidence and Information Value using Python](https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb)\n",
    "2. Обсуждение плюсов использования WoE в логистической регрессии - [Replacing Variables by WoE in Logistic Regression](https://stats.stackexchange.com/questions/189568/replacing-variables-by-woe-weight-of-evidence-in-logistic-regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Stacking and Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбор решений победителей, которые применяли несколько моделей, а также стэкинг:\n",
    "\n",
    "- [DonorsChoose.org Application Screening: Predict whether teachers' project proposals are accepted](https://www.kaggle.com/shadowwarrior/1st-place-solution)\n",
    "- [Otto Group Product Classification Challenge: Classify products into the correct category](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335)\n",
    "- [House Prices: Advanced Regression Techniques: Predict sales prices and practice feature engineering, RFs, and gradient boosting](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard)\n",
    "\n",
    "А также:\n",
    "- [Подборка ссылок на решения победителей](https://www.kaggle.com/rajiao/winning-solutions-of-kaggle-competitions)\n",
    "- [Tips for stacking and blending](https://www.kaggle.com/zaochenye/tips-for-stacking-and-blending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6YHvcPvdfKS"
   },
   "source": [
    "## Дополнительные материалы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Метод градиентного спуска](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%81%D0%BF%D1%83%D1%81%D0%BA%D0%B0)\n",
    "\n",
    "2. [Шум в больших данных. Анализ на основе энтропии информации](https://habr.com/ru/post/458868/)\n",
    "\n",
    "3. [Поиск аномалий (Anomaly Detection)](https://dyakonov.org/2017/04/19/%D0%BF%D0%BE%D0%B8%D1%81%D0%BA-%D0%B0%D0%BD%D0%BE%D0%BC%D0%B0%D0%BB%D0%B8%D0%B9-anomaly-detection/)\n",
    "\n",
    "4. [Готовим данные для анализа правильно](https://habr.com/ru/post/342366/)\n",
    "\n",
    "5. [Смещение (bias) и разброс (variance)](https://dyakonov.org/2018/04/25/%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D0%B5-bias-%D0%B8-%D1%80%D0%B0%D0%B7%D0%B1%D1%80%D0%BE%D1%81-variance-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82/)\n",
    "\n",
    "6. [Оптимизация гиперпараметров](https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пожелания и напутствия :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/meme_1.jpg\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/meme_2.jpg\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/meme_3.jpeg\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
